# Using Generative AI Responsibly

## Responsible AI Principles

The excitement around Generative AI requires a responsible approach. The key principles of Responsible AI include:

- **Fairness**
- **Inclusiveness**
- **Reliability/Safety**
- **Security & Privacy**
- **Transparency**
- **Accountability**

These principles should guide the use of Generative AI in our products.

## Why Prioritize Responsible AI

Taking a human-centric approach ensures the best results. Generative AI's power to create useful content comes with risks, such as:

### Hallucinations

LLMs may produce incorrect or nonsensical content, which can mislead users and harm the credibility of your product.

### Harmful Content

Risks include generating:

- Instructions for self-harm or violence.
- Hateful or demeaning content.
- Guidance on illegal activities.
- Sexually explicit content.

### Lack of Fairness

AI systems must be free from bias and discrimination to treat everyone equally and avoid reinforcing exclusionary worldviews.

## How to Use Generative AI Responsibly

### Measure Potential Harms

Test diverse prompts to measure potential harms, particularly relevant to your product's domain.

### Mitigate Potential Harms

Mitigate harms through:

- **Model**: Choose and fine-tune the right model.
- **Safety System**: Implement content filtering and detect unwanted activity.
- **Metaprompt**: Direct the model using system inputs and trusted sources.
- **User Experience**: Design the UI/UX to limit harmful interactions and be transparent about the AIâ€™s capabilities.

### Evaluate Model

Regularly evaluate the model's performance to ensure accuracy, groundedness, and relevance.

### Operate a Responsible Generative AI Solution

Build operational practices including compliance with regulatory policies and incident handling.
